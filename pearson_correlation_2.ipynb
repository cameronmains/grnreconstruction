{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd8e8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fiveFiftyPath = r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\5_mr_50_cond\\simulated_noNoise.txt\"\n",
    "fourtyFiftyPath = r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\5_mr_50_cond\\simulated_noNoise.txt\"\n",
    "hundidHundidPath = r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\5_mr_50_cond\\simulated_noNoise.txt\"\n",
    "\n",
    "\n",
    "data_5_mr_50_cond = np.loadtxt(fiveFiftyPath)\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\5_mr_50_cond\\simulated_noNoiseAll\", data_5_mr_50_cond)\n",
    "data_5_mr_50_cond_tfs = data_5_mr_50_cond[1:,:100]\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\5_mr_50_cond\\simulated_noNoiseTFs\", data_5_mr_50_cond_tfs)\n",
    "data_5_mr_50_cond_tgs = data_5_mr_50_cond[1:,100:200]\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\5_mr_50_cond\\simulated_noNoiseTGs\", data_5_mr_50_cond_tgs)\n",
    "\n",
    "data_40_mr_50_cond = np.loadtxt(fourtyFiftyPath)\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\40_mr_50_cond\\simulated_noNoiseAll\", data_40_mr_50_cond)\n",
    "data_40_mr_50_cond_tfs = data_40_mr_50_cond[1:,:100]\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\40_mr_50_cond\\simulated_noNoiseTFs\", data_40_mr_50_cond_tfs)\n",
    "data_40_mr_50_cond_tgs = data_40_mr_50_cond[1:,100:200]\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\40_mr_50_cond\\simulated_noNoiseTGs\", data_40_mr_50_cond_tgs)\n",
    "\n",
    "data_100_mr_100_cond = np.loadtxt(hundidHundidPath)\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\100_mr_100_cond\\simulated_noNoiseAll\", data_100_mr_100_cond)\n",
    "data_100_mr_100_cond_tfs = data_100_mr_100_cond[1:,:100]\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\100_mr_100_cond\\simulated_noNoiseTFs\", data_100_mr_100_cond_tfs)\n",
    "data_100_mr_100_cond_tgs = data_100_mr_100_cond[1:,100:200]\n",
    "np.save(r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\100_mr_100_cond\\simulated_noNoiseTGs\", data_100_mr_100_cond_tgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6f10a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth_matrix(ground_truth_file):\n",
    "    \"\"\"\n",
    "    Create a ground truth adjacency matrix from the edge list file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ground_truth_file : str\n",
    "        Path to the ground truth file (bipartite_GRN.csv)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Binary adjacency matrix representing the ground truth GRN\n",
    "    \"\"\"\n",
    "    # Read ground truth GRN\n",
    "    ground_truth_edges = np.loadtxt(ground_truth_file, delimiter=',', dtype=int)\n",
    "    \n",
    "    # Create ground truth adjacency matrix\n",
    "    n_tf = 100\n",
    "    n_g = 100\n",
    "    ground_truth_matrix = np.zeros((n_tf, n_g), dtype=int)\n",
    "    \n",
    "    # Fill ground truth adjacency matrix\n",
    "    for edge in ground_truth_edges:\n",
    "        tf_id = int(edge[0])  # TF id \n",
    "        gene_id = int(edge[1]) - 100  # Target gene id, adjusted for matrix indexing\n",
    "        \n",
    "        # Ensure indices are within bounds\n",
    "        if 0 <= tf_id < n_tf and 0 <= gene_id < n_g:\n",
    "            ground_truth_matrix[tf_id, gene_id] = 1\n",
    "        else:\n",
    "            print(f\"Warning: Edge {tf_id} -> {gene_id+100} is out of bounds and will be ignored\")\n",
    "    \n",
    "    # Print some statistics\n",
    "    num_edges = np.sum(ground_truth_matrix)\n",
    "    print(f\"Ground truth matrix created: {ground_truth_matrix.shape}\")\n",
    "    print(f\"Number of regulatory interactions: {num_edges}\")\n",
    "    print(f\"Average number of TFs regulating each gene: {num_edges/n_g:.2f}\")\n",
    "    print(f\"Average number of genes regulated by each TF: {num_edges/n_tf:.2f}\")\n",
    "    \n",
    "    return ground_truth_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f162b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grn_reconstruction(expression_file, ground_truth_file, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Run the complete GRN reconstruction pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    expression_file : str\n",
    "        Path to the expression data file\n",
    "    ground_truth_file : str\n",
    "        Path to the ground truth file\n",
    "    threshold : float\n",
    "        Correlation threshold\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with results and metrics\n",
    "    \"\"\"\n",
    "    # Load expression data\n",
    "    print(\"Loading expression data...\")\n",
    "    expression_data = np.loadtxt(expression_file)\n",
    "    print(f\"Expression data shape: {expression_data.shape}\")\n",
    "    \n",
    "    # Extract header and values\n",
    "    gene_ids = expression_data[0, :].astype(int)\n",
    "    exp_values = expression_data[1:, :]\n",
    "    \n",
    "    # Verify data structure\n",
    "    print(f\"Gene IDs range: {gene_ids.min()} to {gene_ids.max()}\")\n",
    "    print(f\"Number of conditions: {exp_values.shape[0]}\")\n",
    "    print(f\"First few values:\\n{exp_values[:3, :5]}\")\n",
    "    \n",
    "    # Load ground truth\n",
    "    print(\"\\nLoading ground truth...\")\n",
    "    #ground_truth_matrix = create_ground_truth_matrix(ground_truth_file)\n",
    "    def create_ground_truth_matrix(ground_truth_file):\n",
    "\n",
    "        # Read ground truth GRN\n",
    "        ground_truth_edges = np.loadtxt(ground_truth_file, delimiter=',', dtype=int)\n",
    "    \n",
    "        # Create ground truth adjacency matrix\n",
    "        n_tf = 100\n",
    "        n_g = 100\n",
    "        ground_truth_matrix = np.zeros((n_tf, n_g), dtype=int)\n",
    "    \n",
    "        # Fill ground truth adjacency matrix\n",
    "        for edge in ground_truth_edges:\n",
    "            tf_id = int(edge[0])  # TF id \n",
    "            gene_id = int(edge[1]) - 100  # Target gene id, adjusted for matrix indexing\n",
    "        \n",
    "            # Ensure indices are within bounds\n",
    "            if 0 <= tf_id < n_tf and 0 <= gene_id < n_g:\n",
    "                ground_truth_matrix[tf_id, gene_id] = 1\n",
    "            else:\n",
    "                print(f\"Warning: Edge {tf_id} -> {gene_id+100} is out of bounds and will be ignored\")\n",
    "    \n",
    "        # Print some statistics\n",
    "        num_edges = np.sum(ground_truth_matrix)\n",
    "        print(f\"Ground truth matrix created: {ground_truth_matrix.shape}\")\n",
    "        print(f\"Number of regulatory interactions: {num_edges}\")\n",
    "        print(f\"Average number of TFs regulating each gene: {num_edges/n_g:.2f}\")\n",
    "        print(f\"Average number of genes regulated by each TF: {num_edges/n_tf:.2f}\")\n",
    "    \n",
    "        return ground_truth_matrix\n",
    "    \n",
    "    ground_truth_matrix = create_ground_truth_matrix(ground_truth_file)\n",
    "    # Extract TF and target gene expression\n",
    "    tf_data = exp_values[:, :100]\n",
    "    target_data = exp_values[:, 100:200]\n",
    "    \n",
    "    # Standardize data\n",
    "    print(\"\\nStandardizing data...\")\n",
    "    scaler = StandardScaler()\n",
    "    tf_data_scaled = scaler.fit_transform(tf_data)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    target_data_scaled = scaler.fit_transform(target_data)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    print(\"\\nCalculating correlations...\")\n",
    "    correlation_matrix = np.zeros((100, 100))\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            correlation_matrix[i, j] = np.corrcoef(tf_data_scaled[:, i], \n",
    "                                                 target_data_scaled[:, j])[0, 1]\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    print(f\"\\nCreating adjacency matrix with threshold {threshold}...\")\n",
    "    adjacency_matrix = np.zeros((100, 100), dtype=int)\n",
    "    adjacency_matrix[abs(correlation_matrix) >= threshold] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'correlation_matrix': correlation_matrix,\n",
    "        'adjacency_matrix': adjacency_matrix,\n",
    "        'ground_truth_matrix': ground_truth_matrix,\n",
    "        #'metrics': metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3b75124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grn_accuracy(predicted_adjacency, ground_truth_adjacency):\n",
    "    # Calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.sum((predicted_adjacency == 1) & (ground_truth_adjacency == 1))\n",
    "    fp = np.sum((predicted_adjacency == 1) & (ground_truth_adjacency == 0))\n",
    "    tn = np.sum((predicted_adjacency == 0) & (ground_truth_adjacency == 0))\n",
    "    fn = np.sum((predicted_adjacency == 0) & (ground_truth_adjacency == 1))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    #return accuracy, precision, recall, f1_score, tp, fp, tn, fn\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'true_negatives': tn,\n",
    "        'false_negatives': fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dfec2312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading expression data...\n",
      "Expression data shape: (51, 200)\n",
      "Gene IDs range: 0 to 199\n",
      "Number of conditions: 50\n",
      "First few values:\n",
      "[[ 3.52  7.57  6.78  4.53  6.94]\n",
      " [ 4.77  2.59 10.5   6.69  5.19]\n",
      " [ 2.02  2.51  7.57  3.86  4.3 ]]\n",
      "\n",
      "Loading ground truth...\n",
      "Ground truth matrix created: (100, 100)\n",
      "Number of regulatory interactions: 487\n",
      "Average number of TFs regulating each gene: 4.87\n",
      "Average number of genes regulated by each TF: 4.87\n",
      "\n",
      "Standardizing data...\n",
      "\n",
      "Calculating correlations...\n",
      "\n",
      "Creating adjacency matrix with threshold 0.3...\n",
      "\n",
      "Evaluating performance...\n",
      "GRN Reconstruction Results:\n",
      "Accuracy: 0.4134\n",
      "Precision: 0.0505\n",
      "Recall: 0.6201\n",
      "F1 Score: 0.0934\n",
      "True Positives: 302\n",
      "False Positives: 5681\n",
      "True Negatives: 3832\n",
      "False Negatives: 185\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load ground truth\n",
    "    ground_truth_path = r\"C:\\Users\\crmai\\OneDrive\\Documents\\GT Spring 2025\\BMED 6517\\Project1_updated_021125\\100_mr_100_cond\\bipartite_GRN.csv\"\n",
    "    #ground_truth_matrix = create_ground_truth_matrix(ground_truth_path)\n",
    "\n",
    "    # Generate predictions using correlation or other methods\n",
    "    #predicted_matrix = build_improved_grn_adjacency_matrix(data_100_mr_100_cond, threshold=0.5)\n",
    "    \n",
    "    results = run_grn_reconstruction(hundidHundidPath, ground_truth_path, threshold=0.3)\n",
    "    correlation_matrix = results['correlation_matrix']\n",
    "    adjacency_matrix = results['adjacency_matrix']\n",
    "    ground_truth_matrix = results['ground_truth_matrix']\n",
    "\n",
    "    # Evaluate performance\n",
    "    print(\"\\nEvaluating performance...\")\n",
    "    metrics = evaluate_grn_accuracy(adjacency_matrix, ground_truth_matrix)\n",
    "\n",
    "    # Print results\n",
    "    '''print(\"\\nGRN Reconstruction Results:\")\n",
    "    print(\"\\naccuracy: \", {accuracy})\n",
    "    print(\"\\nprecision: \", {precision})\n",
    "    print(\"\\nrecall: \", {recall})\n",
    "    print(\"\\nf1: \", {f1_score})\n",
    "    print({tp})\n",
    "    print({fp})\n",
    "    print({tn})\n",
    "    print({fn})'''\n",
    "    print(\"GRN Reconstruction Results:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"True Positives: {metrics['true_positives']}\")\n",
    "    print(f\"False Positives: {metrics['false_positives']}\")\n",
    "    print(f\"True Negatives: {metrics['true_negatives']}\")\n",
    "    print(f\"False Negatives: {metrics['false_negatives']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
